{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\", \"pyspark-shell\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complex processing and data pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to data pipelines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of steps to process data from sources to final output. A data pipeline can consist of any number of steps or components and can span many systems. A data pipeline consists of inputs, transformations and outputs of those steps. There is also validation and analysis steps. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F \n",
    "departures_df = spark.read.csv(\"AA_DFW_2015_Departures_Short.csv\", header=True)\n",
    "departures_df = departures_df.filter(departures_df[3] > 0)\n",
    "departures_df = departures_df.withColumn(\"id\", F.monotonically_increasing_id())\n",
    "# departures_df.write.json(\"output.json\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data handling techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark's CSV parser can automatically remove blank lines, can remove comments using an optional argument (comment=...), can handle header fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing commented lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full count: 32794\n",
      "Comment count: 1416\n",
      "Remaining count: 31378\n"
     ]
    }
   ],
   "source": [
    "annotations_df = spark.read.csv('annotations.csv', sep=\"|\", header=True)\n",
    "full_count = annotations_df.count()\n",
    "\n",
    "comment_count = annotations_df.where(F.col('_c0').startswith('#')).count()\n",
    "no_comments_df = spark.read.csv('annotations.csv', sep=\"|\", comment='#',header=True)\n",
    "no_comments_count = no_comments_df.count()\n",
    "print(\"Full count: %d\\nComment count: %d\\nRemaining count: %d\" % (full_count, comment_count, no_comments_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing invalid rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial count: 31378\n",
      "Final count: 20580\n"
     ]
    }
   ],
   "source": [
    "tmp_fields = F.split(no_comments_df[\"_c0\"], \" \")\n",
    "initial_count = no_comments_df.count()\n",
    "no_comments_df = no_comments_df.withColumn(\"colcount\", F.size(tmp_fields))\n",
    "annotations_df_filtered = no_comments_df.filter(~(no_comments_df.colcount < 5))\n",
    "\n",
    "final_count = annotations_df_filtered.count()\n",
    "print(\"Initial count: %d\\nFinal count: %d\" % (initial_count, final_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------+--------+\n",
      "|_c0                                                                                  |colcount|\n",
      "+-------------------------------------------------------------------------------------+--------+\n",
      "|02110627 n02110627_12938 200 300 affenpinscher,0,9,173,298                           |5       |\n",
      "|02093754 n02093754_1148 500 378 Border_terrier,73,127,341,335                        |5       |\n",
      "|%s %s 800 600 Shetland_sheepdog,124,87,576,514                                       |5       |\n",
      "|02104029 n02104029_63 500 375 kuvasz,0,0,499,327                                     |5       |\n",
      "|02111500 n02111500_5137 500 375 Great_Pyrenees,124,225,403,374                       |5       |\n",
      "|02104365 n02104365_7518 500 333 schipperke,146,29,416,309                            |5       |\n",
      "|02105056 n02105056_2834 500 375 groenendael,168,0,469,374                            |5       |\n",
      "|02093647 n02093647_541 500 333 Bedlington_terrier,10,12,462,332                      |5       |\n",
      "|02098413 n02098413_1355 500 375 Lhasa,39,1,499,373                                   |5       |\n",
      "|02093859 n02093859_2309 330 500 Kerry_blue_terrier,17,16,300,482                     |5       |\n",
      "|02100583 n02100583_702 500 333 vizsla,112,93,276,236                                 |5       |\n",
      "|02109961 n02109961_1017 475 500 Eskimo_dog,43,20,472,461                             |5       |\n",
      "|02096177 n02096177_11642 500 375 cairn,71,2,319,302                                  |5       |\n",
      "|02108000 n02108000_3491 600 450 EntleBucher,307,94,515,448 EntleBucher,101,33,330,448|6       |\n",
      "|02085782 n02085782_1731 600 449 Japanese_spaniel,23,0,598,435                        |5       |\n",
      "|02109047 n02109047_888 410 368 Great_Dane,51,36,355,332                              |5       |\n",
      "|02110185 n02110185_2736 259 500 Siberian_husky,7,2,235,498                           |5       |\n",
      "|02086646 n02086646_2970 500 400 Blenheim_spaniel,25,66,401,387                       |5       |\n",
      "|02096177 n02096177_6751 500 375 cairn,82,2,472,369                                   |5       |\n",
      "|02098413 n02098413_1713 500 333 Lhasa,141,40,423,185                                 |5       |\n",
      "+-------------------------------------------------------------------------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "annotations_df_filtered.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------+--------+--------+---------------+-----+------+--------------------------------------------------------------------------------------------+\n",
      "|_c0                                                                                  |colcount|folder  |filename       |width|height|split_cols                                                                                  |\n",
      "+-------------------------------------------------------------------------------------+--------+--------+---------------+-----+------+--------------------------------------------------------------------------------------------+\n",
      "|02110627 n02110627_12938 200 300 affenpinscher,0,9,173,298                           |5       |02110627|n02110627_12938|200  |300   |[02110627, n02110627_12938, 200, 300, affenpinscher,0,9,173,298]                            |\n",
      "|02093754 n02093754_1148 500 378 Border_terrier,73,127,341,335                        |5       |02093754|n02093754_1148 |500  |378   |[02093754, n02093754_1148, 500, 378, Border_terrier,73,127,341,335]                         |\n",
      "|%s %s 800 600 Shetland_sheepdog,124,87,576,514                                       |5       |%s      |%s             |800  |600   |[%s, %s, 800, 600, Shetland_sheepdog,124,87,576,514]                                        |\n",
      "|02104029 n02104029_63 500 375 kuvasz,0,0,499,327                                     |5       |02104029|n02104029_63   |500  |375   |[02104029, n02104029_63, 500, 375, kuvasz,0,0,499,327]                                      |\n",
      "|02111500 n02111500_5137 500 375 Great_Pyrenees,124,225,403,374                       |5       |02111500|n02111500_5137 |500  |375   |[02111500, n02111500_5137, 500, 375, Great_Pyrenees,124,225,403,374]                        |\n",
      "|02104365 n02104365_7518 500 333 schipperke,146,29,416,309                            |5       |02104365|n02104365_7518 |500  |333   |[02104365, n02104365_7518, 500, 333, schipperke,146,29,416,309]                             |\n",
      "|02105056 n02105056_2834 500 375 groenendael,168,0,469,374                            |5       |02105056|n02105056_2834 |500  |375   |[02105056, n02105056_2834, 500, 375, groenendael,168,0,469,374]                             |\n",
      "|02093647 n02093647_541 500 333 Bedlington_terrier,10,12,462,332                      |5       |02093647|n02093647_541  |500  |333   |[02093647, n02093647_541, 500, 333, Bedlington_terrier,10,12,462,332]                       |\n",
      "|02098413 n02098413_1355 500 375 Lhasa,39,1,499,373                                   |5       |02098413|n02098413_1355 |500  |375   |[02098413, n02098413_1355, 500, 375, Lhasa,39,1,499,373]                                    |\n",
      "|02093859 n02093859_2309 330 500 Kerry_blue_terrier,17,16,300,482                     |5       |02093859|n02093859_2309 |330  |500   |[02093859, n02093859_2309, 330, 500, Kerry_blue_terrier,17,16,300,482]                      |\n",
      "|02100583 n02100583_702 500 333 vizsla,112,93,276,236                                 |5       |02100583|n02100583_702  |500  |333   |[02100583, n02100583_702, 500, 333, vizsla,112,93,276,236]                                  |\n",
      "|02109961 n02109961_1017 475 500 Eskimo_dog,43,20,472,461                             |5       |02109961|n02109961_1017 |475  |500   |[02109961, n02109961_1017, 475, 500, Eskimo_dog,43,20,472,461]                              |\n",
      "|02096177 n02096177_11642 500 375 cairn,71,2,319,302                                  |5       |02096177|n02096177_11642|500  |375   |[02096177, n02096177_11642, 500, 375, cairn,71,2,319,302]                                   |\n",
      "|02108000 n02108000_3491 600 450 EntleBucher,307,94,515,448 EntleBucher,101,33,330,448|6       |02108000|n02108000_3491 |600  |450   |[02108000, n02108000_3491, 600, 450, EntleBucher,307,94,515,448, EntleBucher,101,33,330,448]|\n",
      "|02085782 n02085782_1731 600 449 Japanese_spaniel,23,0,598,435                        |5       |02085782|n02085782_1731 |600  |449   |[02085782, n02085782_1731, 600, 449, Japanese_spaniel,23,0,598,435]                         |\n",
      "|02109047 n02109047_888 410 368 Great_Dane,51,36,355,332                              |5       |02109047|n02109047_888  |410  |368   |[02109047, n02109047_888, 410, 368, Great_Dane,51,36,355,332]                               |\n",
      "|02110185 n02110185_2736 259 500 Siberian_husky,7,2,235,498                           |5       |02110185|n02110185_2736 |259  |500   |[02110185, n02110185_2736, 259, 500, Siberian_husky,7,2,235,498]                            |\n",
      "|02086646 n02086646_2970 500 400 Blenheim_spaniel,25,66,401,387                       |5       |02086646|n02086646_2970 |500  |400   |[02086646, n02086646_2970, 500, 400, Blenheim_spaniel,25,66,401,387]                        |\n",
      "|02096177 n02096177_6751 500 375 cairn,82,2,472,369                                   |5       |02096177|n02096177_6751 |500  |375   |[02096177, n02096177_6751, 500, 375, cairn,82,2,472,369]                                    |\n",
      "|02098413 n02098413_1713 500 333 Lhasa,141,40,423,185                                 |5       |02098413|n02098413_1713 |500  |333   |[02098413, n02098413_1713, 500, 333, Lhasa,141,40,423,185]                                  |\n",
      "+-------------------------------------------------------------------------------------+--------+--------+---------------+-----+------+--------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_cols = F.split(annotations_df_filtered[\"_c0\"], \" \")\n",
    "\n",
    "split_df = annotations_df_filtered.withColumn(\"folder\", split_cols.getItem(0))\n",
    "split_df = split_df.withColumn(\"filename\", split_cols.getItem(1))\n",
    "split_df = split_df.withColumn(\"width\", split_cols.getItem(2))\n",
    "split_df = split_df.withColumn(\"height\", split_cols.getItem(3))\n",
    "\n",
    "split_df = split_df.withColumn(\"split_cols\", split_cols)\n",
    "\n",
    "split_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>colcount</th>\n",
       "      <th>folder</th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>split_cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02110627 n02110627_12938 200 300 affenpinscher...</td>\n",
       "      <td>5</td>\n",
       "      <td>02110627</td>\n",
       "      <td>n02110627_12938</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>[02110627, n02110627_12938, 200, 300, affenpin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02093754 n02093754_1148 500 378 Border_terrier...</td>\n",
       "      <td>5</td>\n",
       "      <td>02093754</td>\n",
       "      <td>n02093754_1148</td>\n",
       "      <td>500</td>\n",
       "      <td>378</td>\n",
       "      <td>[02093754, n02093754_1148, 500, 378, Border_te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>%s %s 800 600 Shetland_sheepdog,124,87,576,514</td>\n",
       "      <td>5</td>\n",
       "      <td>%s</td>\n",
       "      <td>%s</td>\n",
       "      <td>800</td>\n",
       "      <td>600</td>\n",
       "      <td>[%s, %s, 800, 600, Shetland_sheepdog,124,87,57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02104029 n02104029_63 500 375 kuvasz,0,0,499,327</td>\n",
       "      <td>5</td>\n",
       "      <td>02104029</td>\n",
       "      <td>n02104029_63</td>\n",
       "      <td>500</td>\n",
       "      <td>375</td>\n",
       "      <td>[02104029, n02104029_63, 500, 375, kuvasz,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02111500 n02111500_5137 500 375 Great_Pyrenees...</td>\n",
       "      <td>5</td>\n",
       "      <td>02111500</td>\n",
       "      <td>n02111500_5137</td>\n",
       "      <td>500</td>\n",
       "      <td>375</td>\n",
       "      <td>[02111500, n02111500_5137, 500, 375, Great_Pyr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20575</th>\n",
       "      <td>02096585 n02096585_12716 500 335 Boston_bull,1...</td>\n",
       "      <td>5</td>\n",
       "      <td>02096585</td>\n",
       "      <td>n02096585_12716</td>\n",
       "      <td>500</td>\n",
       "      <td>335</td>\n",
       "      <td>[02096585, n02096585_12716, 500, 335, Boston_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20576</th>\n",
       "      <td>02097047 n02097047_1495 375 500 miniature_schn...</td>\n",
       "      <td>5</td>\n",
       "      <td>02097047</td>\n",
       "      <td>n02097047_1495</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>[02097047, n02097047_1495, 375, 500, miniature...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20577</th>\n",
       "      <td>02098413 n02098413_11467 390 390 Lhasa,7,51,27...</td>\n",
       "      <td>5</td>\n",
       "      <td>02098413</td>\n",
       "      <td>n02098413_11467</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>[02098413, n02098413_11467, 390, 390, Lhasa,7,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20578</th>\n",
       "      <td>02112706 n02112706_726 560 615 Brabancon_griff...</td>\n",
       "      <td>5</td>\n",
       "      <td>02112706</td>\n",
       "      <td>n02112706_726</td>\n",
       "      <td>560</td>\n",
       "      <td>615</td>\n",
       "      <td>[02112706, n02112706_726, 560, 615, Brabancon_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20579</th>\n",
       "      <td>02093859 n02093859_3125 229 183 Kerry_blue_ter...</td>\n",
       "      <td>5</td>\n",
       "      <td>02093859</td>\n",
       "      <td>n02093859_3125</td>\n",
       "      <td>229</td>\n",
       "      <td>183</td>\n",
       "      <td>[02093859, n02093859_3125, 229, 183, Kerry_blu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20580 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     _c0  colcount    folder  \\\n",
       "0      02110627 n02110627_12938 200 300 affenpinscher...         5  02110627   \n",
       "1      02093754 n02093754_1148 500 378 Border_terrier...         5  02093754   \n",
       "2         %s %s 800 600 Shetland_sheepdog,124,87,576,514         5        %s   \n",
       "3       02104029 n02104029_63 500 375 kuvasz,0,0,499,327         5  02104029   \n",
       "4      02111500 n02111500_5137 500 375 Great_Pyrenees...         5  02111500   \n",
       "...                                                  ...       ...       ...   \n",
       "20575  02096585 n02096585_12716 500 335 Boston_bull,1...         5  02096585   \n",
       "20576  02097047 n02097047_1495 375 500 miniature_schn...         5  02097047   \n",
       "20577  02098413 n02098413_11467 390 390 Lhasa,7,51,27...         5  02098413   \n",
       "20578  02112706 n02112706_726 560 615 Brabancon_griff...         5  02112706   \n",
       "20579  02093859 n02093859_3125 229 183 Kerry_blue_ter...         5  02093859   \n",
       "\n",
       "              filename width height  \\\n",
       "0      n02110627_12938   200    300   \n",
       "1       n02093754_1148   500    378   \n",
       "2                   %s   800    600   \n",
       "3         n02104029_63   500    375   \n",
       "4       n02111500_5137   500    375   \n",
       "...                ...   ...    ...   \n",
       "20575  n02096585_12716   500    335   \n",
       "20576   n02097047_1495   375    500   \n",
       "20577  n02098413_11467   390    390   \n",
       "20578    n02112706_726   560    615   \n",
       "20579   n02093859_3125   229    183   \n",
       "\n",
       "                                              split_cols  \n",
       "0      [02110627, n02110627_12938, 200, 300, affenpin...  \n",
       "1      [02093754, n02093754_1148, 500, 378, Border_te...  \n",
       "2      [%s, %s, 800, 600, Shetland_sheepdog,124,87,57...  \n",
       "3      [02104029, n02104029_63, 500, 375, kuvasz,0,0,...  \n",
       "4      [02111500, n02111500_5137, 500, 375, Great_Pyr...  \n",
       "...                                                  ...  \n",
       "20575  [02096585, n02096585_12716, 500, 335, Boston_b...  \n",
       "20576  [02097047, n02097047_1495, 375, 500, miniature...  \n",
       "20577  [02098413, n02098413_11467, 390, 390, Lhasa,7,...  \n",
       "20578  [02112706, n02112706_726, 560, 615, Brabancon_...  \n",
       "20579  [02093859, n02093859_3125, 229, 183, Kerry_blu...  \n",
       "\n",
       "[20580 rows x 7 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+-----+------+--------------------+\n",
      "|  folder|       filename|width|height|            dog_list|\n",
      "+--------+---------------+-----+------+--------------------+\n",
      "|02110627|n02110627_12938|  200|   300|[affenpinscher,0,...|\n",
      "|02093754| n02093754_1148|  500|   378|[Border_terrier,7...|\n",
      "|      %s|             %s|  800|   600|[Shetland_sheepdo...|\n",
      "|02104029|   n02104029_63|  500|   375|[kuvasz,0,0,499,327]|\n",
      "|02111500| n02111500_5137|  500|   375|[Great_Pyrenees,1...|\n",
      "|02104365| n02104365_7518|  500|   333|[schipperke,146,2...|\n",
      "|02105056| n02105056_2834|  500|   375|[groenendael,168,...|\n",
      "|02093647|  n02093647_541|  500|   333|[Bedlington_terri...|\n",
      "|02098413| n02098413_1355|  500|   375|[Lhasa,39,1,499,373]|\n",
      "|02093859| n02093859_2309|  330|   500|[Kerry_blue_terri...|\n",
      "|02100583|  n02100583_702|  500|   333|[vizsla,112,93,27...|\n",
      "|02109961| n02109961_1017|  475|   500|[Eskimo_dog,43,20...|\n",
      "|02096177|n02096177_11642|  500|   375|[cairn,71,2,319,302]|\n",
      "|02108000| n02108000_3491|  600|   450|[EntleBucher,307,...|\n",
      "|02085782| n02085782_1731|  600|   449|[Japanese_spaniel...|\n",
      "|02109047|  n02109047_888|  410|   368|[Great_Dane,51,36...|\n",
      "|02110185| n02110185_2736|  259|   500|[Siberian_husky,7...|\n",
      "|02086646| n02086646_2970|  500|   400|[Blenheim_spaniel...|\n",
      "|02096177| n02096177_6751|  500|   375|[cairn,82,2,472,369]|\n",
      "|02098413| n02098413_1713|  500|   333|[Lhasa,141,40,423...|\n",
      "+--------+---------------+-----+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "def retriever(cols, colcount):\n",
    "    return cols[4:colcount]\n",
    "\n",
    "udfRetriever = F.udf(retriever, ArrayType(StringType()))\n",
    "\n",
    "split_df_parsed = split_df.withColumn(\"dog_list\", udfRetriever(split_df.split_cols, split_df.colcount))\n",
    "\n",
    "split_df_parsed = split_df_parsed.drop(\"_c0\").drop(\"split_cols\").drop(\"colcount\")\n",
    "split_df_parsed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation is verifying that a dataset complies with the expected format included number of rows and columns. \n",
    "\n",
    "One technique to validate data in Spark is using joins to verify th content of a DataFrame matches a known set. It is fast vs validating individual rows against a long list of entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate rows via join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 20580\n",
      "After: 19956\n"
     ]
    }
   ],
   "source": [
    "valid_folders_df = spark.read.csv(\"valid_folders.csv\",header=True)\n",
    "valid_folders_df = valid_folders_df.toPandas()\n",
    "valid_folders_df[\"_c0\"] = valid_folders_df[\"_c0\"].str.split()\n",
    "for i in range(1105):\n",
    "    valid_folders_df.loc[i] = valid_folders_df.loc[i][0][1]\n",
    "valid_folders_df = spark.createDataFrame(valid_folders_df)\n",
    "\n",
    "valid_folders_df = valid_folders_df.withColumnRenamed(\"_c0\", \"folder\")\n",
    "split_count = split_df_parsed.count()\n",
    "\n",
    "joined_df = split_df_parsed.join(F.broadcast(valid_folders_df), \"folder\")\n",
    "joined_count = joined_df.count()\n",
    "print(\"Before: %d\\nAfter: %d\" % (split_count, joined_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining invalid rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " split_df:\t20580\n",
      " joined_df:\t19956\n",
      " invalid_df: \t624\n",
      "1 distinct invalid folders found\n"
     ]
    }
   ],
   "source": [
    "split_count = split_df_parsed.count()\n",
    "joined_count = joined_df.count()\n",
    "\n",
    "invalid_df = split_df_parsed.join(F.broadcast(joined_df),\"folder\", \"left_anti\")\n",
    "invalid_count = invalid_df.count()\n",
    "print(\" split_df:\\t%d\\n joined_df:\\t%d\\n invalid_df: \\t%d\" % (split_count, joined_count, invalid_count))\n",
    "\n",
    "invalid_folder_count = invalid_df.select(\"folder\").distinct().count()\n",
    "print(\"%d distinct invalid folders found\" % invalid_folder_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final analysis and delivery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis calculations are the process of using the columns of data in a DataFrame to compute some useful value using Spark's functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dog parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|dog_list                          |\n",
      "+----------------------------------+\n",
      "|[affenpinscher,0,9,173,298]       |\n",
      "|[Border_terrier,73,127,341,335]   |\n",
      "|[kuvasz,0,0,499,327]              |\n",
      "|[Great_Pyrenees,124,225,403,374]  |\n",
      "|[schipperke,146,29,416,309]       |\n",
      "|[groenendael,168,0,469,374]       |\n",
      "|[Bedlington_terrier,10,12,462,332]|\n",
      "|[Lhasa,39,1,499,373]              |\n",
      "|[Kerry_blue_terrier,17,16,300,482]|\n",
      "|[vizsla,112,93,276,236]           |\n",
      "+----------------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(joined_df.select(\"dog_list\").show(10, truncate=False))\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType\n",
    "DogType = StructType([\n",
    "    StructField(\"breed\", StringType(), False),\n",
    "    StructField(\"start_x\", IntegerType(), False),\n",
    "    StructField(\"start_y\", IntegerType(), False),\n",
    "    StructField(\"end_x\", IntegerType(), False),\n",
    "    StructField(\"end_y\", IntegerType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per image count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|size(dogs)|\n",
      "+----------+\n",
      "|         1|\n",
      "|         1|\n",
      "|         1|\n",
      "|         1|\n",
      "|         1|\n",
      "|         1|\n",
      "|         1|\n",
      "|         1|\n",
      "|         1|\n",
      "|         1|\n",
      "+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def dogParse(doglist):\n",
    "    dogs = []\n",
    "    for dog in doglist:\n",
    "        (breed, start_x, start_y, end_x, end_y) = dog.split(\",\")\n",
    "        dogs.append((breed, int(start_x), int(start_y), int(end_x), int(end_y)))\n",
    "    return dogs\n",
    "\n",
    "udfDogParse = F.udf(dogParse, ArrayType(DogType))\n",
    "\n",
    "joined_df = joined_df.withColumn(\"dogs\", udfDogParse(\"dog_list\")).drop(\"dog_list\")\n",
    "joined_df.select(F.size(\"dogs\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage dog pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+-----+------+--------------------+----------+-----------------+\n",
      "|  folder|       filename|width|height|                dogs|dog_pixels|      dog_percent|\n",
      "+--------+---------------+-----+------+--------------------+----------+-----------------+\n",
      "|02110627|n02110627_12938|  200|   300|[{affenpinscher, ...|     49997|83.32833333333333|\n",
      "|02104029|   n02104029_63|  500|   375|[{kuvasz, 0, 0, 4...|    163173|          87.0256|\n",
      "|02105056| n02105056_2834|  500|   375|[{groenendael, 16...|    112574|60.03946666666666|\n",
      "|02093647|  n02093647_541|  500|   333|[{Bedlington_terr...|    144640|86.87087087087087|\n",
      "|02098413| n02098413_1355|  500|   375|[{Lhasa, 39, 1, 4...|    171120|           91.264|\n",
      "|02093859| n02093859_2309|  330|   500|[{Kerry_blue_terr...|    131878|79.92606060606062|\n",
      "|02109961| n02109961_1017|  475|   500|[{Eskimo_dog, 43,...|    189189|79.65852631578947|\n",
      "|02108000| n02108000_3491|  600|   450|[{EntleBucher, 30...|    168667|62.46925925925926|\n",
      "|02085782| n02085782_1731|  600|   449|[{Japanese_spanie...|    250125|92.84521158129176|\n",
      "|02110185| n02110185_2736|  259|   500|[{Siberian_husky,...|    113088|87.32664092664093|\n",
      "+--------+---------------+-----+------+--------------------+----------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def dogPixelCount(doglist):\n",
    "    totalpixels = 0\n",
    "    for dog in doglist:\n",
    "        totalpixels += (dog[3] - dog[1]) * (dog[4] - dog[2])\n",
    "    return totalpixels\n",
    "\n",
    "udfDogPixelCount = F.udf(dogPixelCount, IntegerType())\n",
    "joined_df = joined_df.withColumn(\"dog_pixels\", udfDogPixelCount(\"dogs\"))\n",
    "joined_df = joined_df.withColumn(\"dog_percent\", (joined_df.dog_pixels/(joined_df.width * joined_df.height))*100)\n",
    "joined_df.filter(\"dog_percent > 60\").show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
