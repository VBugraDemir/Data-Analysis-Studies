{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\", \"pyspark-shell\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Transform Select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETS: Extract, transform and select. Extraction is extracting features from raw data. Transformation involves scaling, converting or modifying features. Selection is subset of features.\n",
    "\n",
    "You can define your own function to use with spark. You need to import udf first. To return values you need to import StringType, IntegerType, FloatType, ArrayType or BooleanType from pyspark.sql.types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practicing creating a UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------+\n",
      "|words                                                                             |\n",
      "+----------------------------------------------------------------------------------+\n",
      "|[The, Project, Gutenberg, EBook, of, The, Adventures, of, Sherlock, Holmes]       |\n",
      "|[by, Sir, Arthur, Conan, Doyle]                                                   |\n",
      "|[(#15, in, our, series, by, Sir, Arthur, Conan, Doyle)]                           |\n",
      "|[Copyright, laws, are, changing, all, over, the, world., Be, sure, to, check, the]|\n",
      "|[copyright, laws, for, your, country, before, downloading, or, redistributing]    |\n",
      "|[this, or, any, other, Project, Gutenberg, eBook.]                                |\n",
      "|[This, header, should, be, the, first, thing, seen, when, viewing, this, Project] |\n",
      "|[Gutenberg, file., Please, do, not, remove, it., Do, not, change, or, edit, the]  |\n",
      "|[header, without, written, permission.]                                           |\n",
      "|[Please, read, the, \"legal, small, print\", and, other, information, about, the]   |\n",
      "+----------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+----------------------------------------------------------------------------------+-----------------------------------------------------------------------------+----------------+\n",
      "|words                                                                             |in                                                                           |out             |\n",
      "+----------------------------------------------------------------------------------+-----------------------------------------------------------------------------+----------------+\n",
      "|[The, Project, Gutenberg, EBook, of, The, Adventures, of, Sherlock, Holmes]       |[The, Project, Gutenberg, EBook, of, The, Adventures, of, Sherlock]          |[Holmes]        |\n",
      "|[by, Sir, Arthur, Conan, Doyle]                                                   |[by, Sir, Arthur, Conan]                                                     |[Doyle]         |\n",
      "|[(#15, in, our, series, by, Sir, Arthur, Conan, Doyle)]                           |[(#15, in, our, series, by, Sir, Arthur, Conan]                              |[Doyle)]        |\n",
      "|[Copyright, laws, are, changing, all, over, the, world., Be, sure, to, check, the]|[Copyright, laws, are, changing, all, over, the, world., Be, sure, to, check]|[the]           |\n",
      "|[copyright, laws, for, your, country, before, downloading, or, redistributing]    |[copyright, laws, for, your, country, before, downloading, or]               |[redistributing]|\n",
      "|[this, or, any, other, Project, Gutenberg, eBook.]                                |[this, or, any, other, Project, Gutenberg]                                   |[eBook.]        |\n",
      "|[This, header, should, be, the, first, thing, seen, when, viewing, this, Project] |[This, header, should, be, the, first, thing, seen, when, viewing, this]     |[Project]       |\n",
      "|[Gutenberg, file., Please, do, not, remove, it., Do, not, change, or, edit, the]  |[Gutenberg, file., Please, do, not, remove, it., Do, not, change, or, edit]  |[the]           |\n",
      "|[header, without, written, permission.]                                           |[header, without, written]                                                   |[permission.]   |\n",
      "|[Please, read, the, \"legal, small, print\", and, other, information, about, the]   |[Please, read, the, \"legal, small, print\", and, other, information, about]   |[the]           |\n",
      "+----------------------------------------------------------------------------------+-----------------------------------------------------------------------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.text(\"sherlock.txt\")\n",
    "df = df.filter(~(df.value == \"\"))\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.types import ArrayType, StringType, BooleanType\n",
    "\n",
    "df = df.select(regexp_replace(\"value\", \",\", \"\").alias(\"words\"))\n",
    "df = df.select(regexp_replace(\"words\", \"  \", \" \").alias(\"words\"))\n",
    "split_df = df.select(split(\"words\", \" \").alias(\"words\"))\n",
    "\n",
    "split_df.show(10, truncate=False)\n",
    "\n",
    "\n",
    "in_udf = udf(lambda x: x[0:len(x)-1] if x and len(x) > 1 else [], ArrayType(StringType()))\n",
    "out_udf = udf(lambda x: x[len(x)-1:len(x)] if x and len(x) > 1 else [], ArrayType(StringType()))\n",
    "df2 = split_df.select(\"words\", in_udf(\"words\").alias(\"in\"), out_udf(\"words\").alias(\"out\"))\n",
    "df2.show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonempty_udf = udf(lambda x:  \n",
    "    True if x and x.numNonzeros()\n",
    "    else False, BooleanType())\n",
    "\n",
    "s_udf = udf(lambda x: str(x[0]) if (x and type(x) is list and len(x) > 0) else \"\", StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practicing array column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('words', 'array<string>'), ('in', 'array<string>'), ('out', 'array<string>')]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+\n",
      "|               words|                  in|         out|\n",
      "+--------------------+--------------------+------------+\n",
      "|[On, the, night, ...|[On, the, night, ...|        [to]|\n",
      "|[during, the, sum...|[during, the, sum...|        [in]|\n",
      "|[August, 5, the, ...|[August, 5, the, ...|        [in]|\n",
      "|[[11], Proposed, ...|[[11], Proposed, ...|     [1798.]|\n",
      "|[5, James, Monroe...|[5, James, Monroe...|  [Tompkins]|\n",
      "|   [Friends, the, 5]|      [Friends, the]|         [5]|\n",
      "|[Fundamental, art...|[Fundamental, art...|         [5]|\n",
      "|[Fundamental, ord...|[Fundamental, ord...|         [5]|\n",
      "| [Hooker, Thomas, 5]|    [Hooker, Thomas]|         [5]|\n",
      "|[Hutchinson, Anne...|  [Hutchinson, Anne]|         [5]|\n",
      "|[Williams, Roger,...|[Williams, Roger, 5]|        [42]|\n",
      "|[nucleinate, of, ...|[nucleinate, of, ...|[solution).]|\n",
      "|[freely, as, poss...|[freely, as, poss...|     [hours]|\n",
      "|[out, by, an, exp...|[out, by, an, exp...|         [5]|\n",
      "|[needle, of, plat...|[needle, of, plat...|   [calibre]|\n",
      "|[case;, 5, grains...|[case;, 5, grains...|        [to]|\n",
      "|[durum, 67, per, ...|[durum, 67, per, ...|       [per]|\n",
      "|[methylated, spir...|[methylated, spir...|        [of]|\n",
      "|[absolute, alcoho...|[absolute, alcoho...|       [and]|\n",
      "|[105, o, F., The,...|[105, o, F., The,...|     [1000)]|\n",
      "+--------------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------+------------+\n",
      "|words                                                                                     |in                                                                                  |out         |\n",
      "+------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------+------------+\n",
      "|[On, the, night, of, March, 5, 1770, a, crowd, on, the, streets, of, Boston, began, to]   |[crowd, night, March, a, 1770, On, Boston, the, on, of, began, streets]             |[to]        |\n",
      "|[during, the, summer, and, on, September, 5, the, Congress, duly, assembled, in]          |[Congress, September, the, on, during, duly, assembled, summer, and]                |[in]        |\n",
      "|[August, 5, the, Payne-Aldrich, bill, became, a, law, a, breach, had, been, made, in]     |[August, law, Payne-Aldrich, a, been, bill, the, had, breach, became, made]         |[in]        |\n",
      "|[[11], Proposed, Sept., 5, 1794., Declared, in, force, January, 8, 1798.]                 |[force, Sept., January, [11], Declared, 1794., Proposed, in]                        |[1798.]     |\n",
      "|[5, James, Monroe, , , , , , Va., , Rep., , 1817-1825, , Daniel, D., Tompkins]            |[Va., Rep., Daniel, James, Monroe, 1817-1825, D.]                                   |[Tompkins]  |\n",
      "|[Friends, the, 5]                                                                         |[the, Friends]                                                                      |[]          |\n",
      "|[Fundamental, articles, 5]                                                                |[articles, Fundamental]                                                             |[]          |\n",
      "|[Fundamental, orders, 5]                                                                  |[orders, Fundamental]                                                               |[]          |\n",
      "|[Hooker, Thomas, 5]                                                                       |[Thomas, Hooker]                                                                    |[]          |\n",
      "|[Hutchinson, Anne, 5]                                                                     |[Hutchinson, Anne]                                                                  |[]          |\n",
      "|[Williams, Roger, 5, 42]                                                                  |[Williams, Roger]                                                                   |[42]        |\n",
      "|[nucleinate, of, soda, (16, minims, of, a, 5, per, cent., solution).]                     |[a, (16, minims, cent., per, of, nucleinate, soda]                                  |[solution).]|\n",
      "|[freely, as, possible., Quinine, in, 5, to, 10, grain, doses, every, four, hours]         |[10, four, as, to, possible., in, doses, freely, every, Quinine, grain]             |[hours]     |\n",
      "|[out, by, an, expert, pathologist., For, the, purpose, he, is, supplied, with, from, 5]   |[out, by, pathologist., he, For, purpose, is, supplied, with, expert, the, an, from]|[]          |\n",
      "|[needle, of, platino-iridium, should, be, 5, cm., long, and, of, a, larger, calibre]      |[larger, a, cm., needle, should, platino-iridium, be, of, long, and]                |[calibre]   |\n",
      "|[case;, 5, grains, three, times, a, day, may, suffice, or, it, may, be, necessary, to]    |[or, grains, day, a, three, times, case;, suffice, be, it, may, necessary]          |[to]        |\n",
      "|[durum, 67, per, cent., olive, oil, 5, per, cent., oil, of, eucalyptus, 2, per]           |[olive, oil, cent., 67, per, of, durum, eucalyptus]                                 |[per]       |\n",
      "|[methylated, spirit, and, then, painted, with, a, 5, per, cent., solution, of]            |[spirit, a, painted, with, cent., methylated, per, then, and, solution]             |[of]        |\n",
      "|[absolute, alcohol, 10, per, cent., water, and, 5, per, cent., carbolic, acid, and]       |[10, water, and, cent., per, carbolic, alcohol, acid, absolute]                     |[and]       |\n",
      "|[105, o, F., The, addition, of, 5, to, 10, minims, of, adrenalin, solution, (1, in, 1000)]|[10, (1, The, adrenalin, to, minims, addition, F., in, of, 105, solution]           |[1000)]     |\n",
      "+------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import array_contains\n",
    "df2.where(array_contains(\"words\", \"5\")).show()\n",
    "\n",
    "TRIVIAL_TOKENS = {'',  '0',  '1',  '2',  '3',  '4',  '5',  '6',  '7',  '8',  '9',  'b',  'c',  'e',  'f',  'g',  'h',  'j',  'k',  'l',  'm',  'n',  'o',  'p',  'pp',  'q',  'r',  's',  't',  'u',  'v',  'w',  'x',  'y',  'z'}\n",
    "\n",
    "rm_trivial_udf = udf(lambda x:\n",
    "                     list(set(x) - TRIVIAL_TOKENS) if x\n",
    "                     else x,\n",
    "                     ArrayType(StringType()))\n",
    "\n",
    "df_after = df2.withColumn('in', rm_trivial_udf('in')).withColumn('out', rm_trivial_udf('out'))\n",
    "\n",
    "df_after.where(array_contains('words','5')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating feature data for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With numNonzeros() you can check it an array contains at least one item.\n",
    "\n",
    "CountVectorizer is a feature extractor. Its input is an array of strings and converts them into a sparse vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a UDF for vector data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|            output|\n",
      "+------------------+\n",
      "|(12847,[65],[1.0])|\n",
      "| (12847,[8],[1.0])|\n",
      "|(12847,[47],[1.0])|\n",
      "|(12847,[89],[1.0])|\n",
      "|(12847,[94],[1.0])|\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('output', 'vector')]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "source_data = [\n",
    "    Row(output = Vectors.sparse(12847,[65],[1.0])),\n",
    "    Row(output = Vectors.sparse(12847,[8],[1.0])),\n",
    "    Row(output = Vectors.sparse(12847,[47],[1.0])),\n",
    "    Row(output = Vectors.sparse(12847,[89],[1.0])),\n",
    "    Row(output = Vectors.sparse(12847,[94],[1.0]))\n",
    "              ]\n",
    "df = spark.createDataFrame(source_data)\n",
    "df.show()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|result|\n",
      "+------+\n",
      "|  65.0|\n",
      "|   8.0|\n",
      "|  47.0|\n",
      "|  89.0|\n",
      "|  94.0|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "first_udf = udf(lambda x: float(x.indices[0]), FloatType())\n",
    "\n",
    "df.select(first_udf(\"output\").alias(\"result\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying a UDF to vector data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|            output|label|\n",
      "+------------------+-----+\n",
      "|(12847,[65],[1.0])| 65.0|\n",
      "| (12847,[8],[1.0])|  8.0|\n",
      "|(12847,[47],[1.0])| 47.0|\n",
      "|(12847,[89],[1.0])| 89.0|\n",
      "|(12847,[94],[1.0])| 94.0|\n",
      "+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new = df.withColumn(\"label\", first_udf(\"output\"))\n",
    "df_new.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming text to vector format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumnRenamed(\"sentence\", \"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"vec\")\n",
    "model = cv.fit(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumnRenamed(\"words\", \"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------+--------+------------------------------------------------------------------------------+\n",
      "|in                                                                 |out     |invec                                                                         |\n",
      "+-------------------------------------------------------------------+--------+------------------------------------------------------------------------------+\n",
      "|[The, Project, Gutenberg, EBook, of, The, Adventures, of, Sherlock]|[Holmes]|(69609,[1,20,516,1139,1275,13924,30142],[2.0,2.0,1.0,1.0,1.0,1.0,1.0])        |\n",
      "|[by, Sir, Arthur, Conan]                                           |[Doyle] |(69609,[16,3434,4703,21302],[1.0,1.0,1.0,1.0])                                |\n",
      "|[(#15, in, our, series, by, Sir, Arthur, Conan]                    |[Doyle)]|(69609,[6,16,98,1226,3434,4703,21302,61595],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "+-------------------------------------------------------------------+--------+------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+------------------------------------------------------------------------------+---------------------+\n",
      "|invec                                                                         |outvec               |\n",
      "+------------------------------------------------------------------------------+---------------------+\n",
      "|(69609,[1,20,516,1139,1275,13924,30142],[2.0,2.0,1.0,1.0,1.0,1.0,1.0])        |(69609,[323],[1.0])  |\n",
      "|(69609,[16,3434,4703,21302],[1.0,1.0,1.0,1.0])                                |(69609,[20000],[1.0])|\n",
      "|(69609,[6,16,98,1226,3434,4703,21302,61595],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|(69609,[49957],[1.0])|\n",
      "+------------------------------------------------------------------------------+---------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = model.transform(df2.withColumnRenamed('in', 'words')).withColumnRenamed('words', 'in').withColumnRenamed('vec', 'invec')\n",
    "result.drop('sentence').show(3, False)\n",
    "\n",
    "result = model.transform(result.withColumnRenamed('out', 'words')).withColumnRenamed('words', 'out').withColumnRenamed('vec', 'outvec')\n",
    "result.select('invec', 'outvec').show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To guess end of the sentence you can use machine learning algorithms. The technique that will be used is not sensitive to the order of the words. This also can be used for recommendations based on a person's viewing history (like video or music). Logistic regression is a suitable approach for this kind of problem if there are two (true and false) differently labeled examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+--------------------+--------------------+----------------+\n",
      "|            sentence|                  in|               out|               invec|              outvec|         endword|\n",
      "+--------------------+--------------------+------------------+--------------------+--------------------+----------------+\n",
      "|[The, Project, Gu...|[The, Project, Gu...|          [Holmes]|(69609,[1,20,516,...| (69609,[323],[1.0])|          Holmes|\n",
      "|[by, Sir, Arthur,...|[by, Sir, Arthur,...|           [Doyle]|(69609,[16,3434,4...|(69609,[20000],[1...|           Doyle|\n",
      "|[(#15, in, our, s...|[(#15, in, our, s...|          [Doyle)]|(69609,[6,16,98,1...|(69609,[49957],[1...|          Doyle)|\n",
      "|[Copyright, laws,...|[Copyright, laws,...|             [the]|(69609,[0,3,32,33...|   (69609,[0],[1.0])|             the|\n",
      "|[copyright, laws,...|[copyright, laws,...|  [redistributing]|(69609,[17,25,84,...|(69609,[15592],[1...|  redistributing|\n",
      "|[this, or, any, o...|[this, or, any, o...|          [eBook.]|(69609,[25,37,71,...|(69609,[28162],[1...|          eBook.|\n",
      "|[This, header, sh...|[This, header, sh...|         [Project]|(69609,[0,21,37,5...| (69609,[516],[1.0])|         Project|\n",
      "|[Gutenberg, file....|[Gutenberg, file....|             [the]|(69609,[18,25,83,...|   (69609,[0],[1.0])|             the|\n",
      "|[header, without,...|[header, without,...|     [permission.]|(69609,[105,1012,...|(69609,[10088],[1...|     permission.|\n",
      "|[Please, read, th...|[Please, read, th...|             [the]|(69609,[0,2,70,71...|   (69609,[0],[1.0])|             the|\n",
      "|[eBook, and, Proj...|[eBook, and, Proj...|              [is]|(69609,[0,1,2,19,...|  (69609,[11],[1.0])|              is|\n",
      "|[important, infor...|[important, infor...|              [in]|(69609,[2,70,86,4...|   (69609,[6],[1.0])|              in|\n",
      "|[how, the, file, ...|[how, the, file, ...|               [a]|(69609,[0,3,21,44...|   (69609,[5],[1.0])|               a|\n",
      "|[donation, to, Pr...|[donation, to, Pr...|       [involved.]|(69609,[2,3,113,2...|(69609,[5684],[1.0])|       involved.|\n",
      "|[**Welcome, To, T...|[**Welcome, To, T...|         [Texts**]|(69609,[1,20,275,...|(69609,[32279],[1...|         Texts**|\n",
      "|[**eBooks, Readab...|[**eBooks, Readab...|          [1971**]|(69609,[2,574,228...|(69609,[25846],[1...|          1971**|\n",
      "|[*****These, eBoo...|[*****These, eBoo...|[Volunteers!*****]|(69609,[1,574,269...|(69609,[24127],[1...|Volunteers!*****|\n",
      "|[Title:, The, Adv...|[Title:, The, Adv...|          [Holmes]|(69609,[1,20,1139...| (69609,[323],[1.0])|          Holmes|\n",
      "|[Author:, Sir, Ar...|[Author:, Sir, Ar...|           [Doyle]|(69609,[3434,4703...|(69609,[20000],[1...|           Doyle|\n",
      "|[Release, Date:, ...|[Release, Date:, ...|          [#1661]]|(69609,[2295,1554...|(69609,[49410],[1...|          #1661]|\n",
      "+--------------------+--------------------+------------------+--------------------+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = result.withColumn(\"endword\", result.out[0])\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+------------------+-------+-----+\n",
      "|            sentence|                  in|  out|               invec|            outvec|endword|label|\n",
      "+--------------------+--------------------+-----+--------------------+------------------+-------+-----+\n",
      "|[weavers, wagon-m...|[weavers, wagon-m...|[him]|(69609,[2,19,1811...|(69609,[30],[1.0])|    him|    1|\n",
      "|[Bute, his, teach...|[Bute, his, teach...|[him]|(69609,[2,7,10,14...|(69609,[30],[1.0])|    him|    1|\n",
      "|[George, III, Wil...|[George, III, Wil...|[him]|(69609,[0,1,8,58,...|(69609,[30],[1.0])|    him|    1|\n",
      "|[addressed, Georg...|[addressed, Georg...|[him]|(69609,[0,2,3,71,...|(69609,[30],[1.0])|    him|    1|\n",
      "|[ease, while, the...|[ease, while, the...|[him]|(69609,[0,1,154,1...|(69609,[30],[1.0])|    him|    1|\n",
      "+--------------------+--------------------+-----+--------------------+------------------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------------------+----------------+--------------------+--------------------+--------------+-----+\n",
      "|            sentence|                  in|             out|               invec|              outvec|       endword|label|\n",
      "+--------------------+--------------------+----------------+--------------------+--------------------+--------------+-----+\n",
      "|[The, Project, Gu...|[The, Project, Gu...|        [Holmes]|(69609,[1,20,516,...| (69609,[323],[1.0])|        Holmes|    0|\n",
      "|[by, Sir, Arthur,...|[by, Sir, Arthur,...|         [Doyle]|(69609,[16,3434,4...|(69609,[20000],[1...|         Doyle|    0|\n",
      "|[(#15, in, our, s...|[(#15, in, our, s...|        [Doyle)]|(69609,[6,16,98,1...|(69609,[49957],[1...|        Doyle)|    0|\n",
      "|[Copyright, laws,...|[Copyright, laws,...|           [the]|(69609,[0,3,32,33...|   (69609,[0],[1.0])|           the|    0|\n",
      "|[copyright, laws,...|[copyright, laws,...|[redistributing]|(69609,[17,25,84,...|(69609,[15592],[1...|redistributing|    0|\n",
      "+--------------------+--------------------+----------------+--------------------+--------------------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df_pos = result.where(\"endword= 'him'\").withColumn(\"label\", lit(1))\n",
    "df_neg = result.where(\"endword <> 'him'\").withColumn(\"label\", lit(0))\n",
    "\n",
    "df_pos.show(5)\n",
    "df_neg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples:  484\n",
      "+--------------------+--------------------+------------------+--------------------+--------------------+----------------+-----+\n",
      "|            sentence|                  in|               out|               invec|              outvec|         endword|label|\n",
      "+--------------------+--------------------+------------------+--------------------+--------------------+----------------+-----+\n",
      "|[Gutenberg, file....|[Gutenberg, file....|             [the]|(69609,[18,25,83,...|   (69609,[0],[1.0])|             the|    0|\n",
      "|[*****These, eBoo...|[*****These, eBoo...|[Volunteers!*****]|(69609,[1,574,269...|(69609,[24127],[1...|Volunteers!*****|    0|\n",
      "|[Author:, Sir, Ar...|[Author:, Sir, Ar...|           [Doyle]|(69609,[3434,4703...|(69609,[20000],[1...|           Doyle|    0|\n",
      "|[\"I, see, it, I, ...|[\"I, see, it, I, ...|          [girl?\"]|(69609,[2,5,7,15,...|(69609,[53992],[1...|          girl?\"|    0|\n",
      "|[\"Then, how, many...|[\"Then, how, many...|         [there?\"]|(69609,[33,113,18...|(69609,[6217],[1.0])|         there?\"|    0|\n",
      "+--------------------+--------------------+------------------+--------------------+--------------------+----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_examples = df_pos.union(df_neg.limit(df_pos.count()))\n",
    "print(\"Number of examples: \", df_examples.count())\n",
    "df_examples.where(\"endword <> 'him'\").sample(False, .1, 42).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_examples = df_examples.select(\"endword\", \"sentence\", \"invec\", \"outvec\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training:  404\n",
      "Number of test:  80\n"
     ]
    }
   ],
   "source": [
    "df_examples = df_examples.withColumnRenamed(\"invec\", \"features\")\n",
    "df_trainset, df_testset = df_examples.randomSplit((0.8,0.2), 42)\n",
    "\n",
    "print(\"Number of training: \", df_trainset.count())\n",
    "print(\"Number of test: \", df_testset.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iterations:  27\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "logistic = LogisticRegression(maxIter = 100, regParam=0.4, elasticNetParam=0.0)\n",
    "df_fitted = logistic.fit(df_trainset)\n",
    "print(\"Training iterations: \", df_fitted.summary.totalIterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting and evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting and evaluating its accuracy. To apply a trained model to the test data, use the transform() operation. Transformation operation returns a dataframe. It adds prediction and probability columns to the data. Prediction is a double but in here it is 0 and 1. The probability column is a vector containing two numbers. The first number is the estimated probability that the prediction is false, the second number is the estimated probability that the prediction is true. To calculate the perfonmance of this classification Area Under Curve can be used.\n",
    "\n",
    "to evaluate the results use model.evaluate(df_test) and model_stats.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test AUC: 0.929\n"
     ]
    }
   ],
   "source": [
    "testSummary = df_fitted.evaluate(df_testset)\n",
    "print(\"test AUC: %.3f\" %testSummary.areaUnderROC) # or testSummary.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----------+\n",
      "|endword|label|prediction|\n",
      "+-------+-----+----------+\n",
      "|    him|    1|       1.0|\n",
      "|    him|    1|       0.0|\n",
      "|    him|    1|       1.0|\n",
      "|    him|    1|       0.0|\n",
      "|    him|    1|       1.0|\n",
      "|    him|    1|       1.0|\n",
      "|    him|    1|       1.0|\n",
      "|    him|    1|       1.0|\n",
      "|    him|    1|       1.0|\n",
      "|    him|    1|       1.0|\n",
      "+-------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fitted.transform(df_testset).select(\"endword\", \"label\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prediction : 1.0\n",
      "label : 1\n",
      "endword : him\n",
      "sentence : ['\"But', 'between', 'not', 'recognizing', 'him', 'as', 'Emperor', 'and', 'calling', 'him']\n",
      "probability : [0.30829130715909214,0.6917086928409079]\n",
      "\n",
      "INCORRECT ==> \n",
      "prediction : 0.0\n",
      "label : 1\n",
      "endword : him\n",
      "sentence : ['\"How', 'about', 'my', 'son', 'Boris', 'Prince?\"', 'said', 'she', 'hurrying', 'after', 'him']\n",
      "probability : [0.5026205303581466,0.4973794696418534]\n",
      "\n",
      "prediction : 1.0\n",
      "label : 1\n",
      "endword : him\n",
      "sentence : ['\"May', 'I', 'call', 'in', 'that', 'boy', 'who', 'was', 'taken', 'prisoner', 'and', 'give', 'him']\n",
      "probability : [0.3678261091637896,0.6321738908362105]\n",
      "\n",
      "INCORRECT ==> \n",
      "prediction : 0.0\n",
      "label : 1\n",
      "endword : him\n",
      "sentence : ['\"Well', 'perhaps\"', 'said', 'he', 'with', 'a', 'sigh.', '\"We', \"don't\", 'expect', 'to', 'get', 'him']\n",
      "probability : [0.6642412270035128,0.33575877299648715]\n",
      "\n",
      "prediction : 1.0\n",
      "label : 1\n",
      "endword : him\n",
      "sentence : ['Alpatych', 'went', 'back', 'to', 'the', 'house', 'called', 'the', 'coachman', 'and', 'told', 'him']\n",
      "probability : [0.40398097875105415,0.5960190212489458]\n",
      "\n",
      "prediction : 1.0\n",
      "label : 1\n",
      "endword : him\n",
      "sentence : ['At', 'that', 'moment', 'as', 'the', 'Horse', 'Guards', 'having', 'passed', 'him']\n",
      "probability : [0.34342882062616537,0.6565711793738347]\n",
      "\n",
      "prediction : 1.0\n",
      "label : 1\n",
      "endword : him\n",
      "sentence : ['Commission', 'for', 'the', 'Revision', 'of', 'the', 'Code', 'of', 'Laws', 'Speranski', 'told', 'him']\n",
      "probability : [0.4728801343095596,0.5271198656904403]\n",
      "\n",
      "prediction : 1.0\n",
      "label : 1\n",
      "endword : him\n",
      "sentence : ['George', 'III', 'William', 'Pitt', 'was', 'turned', 'out', 'of', 'office', 'the', 'king', 'treating', 'him']\n",
      "probability : [0.36024935430535754,0.6397506456946425]\n"
     ]
    }
   ],
   "source": [
    "# predictions = df_fitted.transform(df_testset)\n",
    "fields = ['prediction', 'label', 'endword', 'sentence', 'probability']\n",
    "for x in predictions.take(8):\n",
    "    print()\n",
    "    if x.label != int(x.prediction):\n",
    "        print(\"INCORRECT ==> \")\n",
    "    for y in fields:\n",
    "        print(y,\":\", x[y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN - PREDICT - EVALUATE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
