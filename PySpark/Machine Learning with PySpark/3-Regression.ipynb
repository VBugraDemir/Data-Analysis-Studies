{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\", \"pyspark-shell\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical variables can be converted to indexed numerical values to be used in a model. But in general this is not sufficient for a regression model since number have no objective meaning to make arithmatics on the index. You need to conver the index values into a format in which you can perform meaningful mathematical operations (exploding). You can exploit this by converting the data into a sparse format. Sparse representation simply records the column numbers and value for the non-zero values also you can drop one of the columns. The process of creating dummy variables is called \"One-Hot Encoding\" because only one of the columns created is ever active or \"hot\". \n",
    "\n",
    "    vector = [1,0,0,0,0,7,0,0]\n",
    "    SparseVector(8, [0, 5], [1, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding flight origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The org column in the flights data is a categorical variable, it needs to be one-hot encoded before it can be used in a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+-------+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|org_idx|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+-------+\n",
      "| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351| null|    2.0|\n",
      "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30|    0.0|\n",
      "|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8|    1.0|\n",
      "|  9| 13|  1|     AA|   419|ORD|1236| 10.33|     195|   -5|    0.0|\n",
      "|  4|  2|  5|     AA|   325|ORD| 258|  8.92|      65| null|    0.0|\n",
      "|  5|  2|  1|     UA|   704|SFO| 550|  7.98|     102|    2|    1.0|\n",
      "|  7|  2|  6|     AA|   380|ORD| 733| 10.83|     135|   54|    0.0|\n",
      "|  1| 16|  6|     UA|  1477|ORD|1440|   8.0|     232|   -7|    0.0|\n",
      "|  1| 22|  5|     UA|   620|SJC|1829|  7.98|     250|  -13|    4.0|\n",
      "| 11|  8|  1|     OO|  5590|SFO| 158|  7.77|      60|   88|    1.0|\n",
      "|  4| 26|  1|     AA|  1144|SFO|1464| 13.25|     210|  -10|    1.0|\n",
      "|  4| 25|  0|     AA|   321|ORD| 978| 13.75|     160|   31|    0.0|\n",
      "|  8| 30|  2|     UA|   646|ORD| 719| 13.28|     151|   16|    0.0|\n",
      "|  3| 16|  3|     UA|   107|ORD|1745|   9.0|     264|    3|    0.0|\n",
      "|  0|  3|  4|     AA|  1559|LGA|1097| 17.08|     190|   32|    3.0|\n",
      "|  5|  9|  1|     UA|   770|SFO| 967|  12.7|     158|   20|    1.0|\n",
      "|  3| 10|  4|     B6|   937|ORD|1735| 17.58|     265|  155|    0.0|\n",
      "| 11| 15|  1|     AA|  2303|ORD| 802|  6.75|     160|   23|    0.0|\n",
      "|  8| 18|  4|     UA|   802|SJC| 948|  6.33|     160|   17|    4.0|\n",
      "|  2| 14|  5|     B6|    71|JFK| 944|  6.17|     166|    0|    2.0|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights = spark.read.csv(\"flights.csv\", sep=\",\", header=True, inferSchema=True, nullValue=\"NA\")\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"org\", outputCol=\"org_idx\")\n",
    "indexer_model = indexer.fit(flights)\n",
    "flights = indexer_model.transform(flights)\n",
    "\n",
    "flights.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------------+\n",
      "|org|org_idx|    org_dummy|\n",
      "+---+-------+-------------+\n",
      "|ORD|    0.0|(7,[0],[1.0])|\n",
      "|SFO|    1.0|(7,[1],[1.0])|\n",
      "|JFK|    2.0|(7,[2],[1.0])|\n",
      "|LGA|    3.0|(7,[3],[1.0])|\n",
      "|SJC|    4.0|(7,[4],[1.0])|\n",
      "|SMF|    5.0|(7,[5],[1.0])|\n",
      "|TUS|    6.0|(7,[6],[1.0])|\n",
      "|OGG|    7.0|    (7,[],[])|\n",
      "+---+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "onehot = OneHotEncoder(inputCols=[\"org_idx\"], outputCols=[\"org_dummy\"])\n",
    "onehot = onehot.fit(flights)\n",
    "flights_onehot = onehot.transform(flights)\n",
    "flights_onehot.select(\"org\", \"org_idx\", \"org_dummy\").distinct().sort(\"org_idx\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the \"OGG\"'s org_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression is for prediction numeric values. MSE (mean squared error) is used to find the mest modeul by minimizing a loss function (min residues). \n",
    "\n",
    "Classes expect to find the target data in a column called \"label\". If it not named label you have to specify the target column. \n",
    "\n",
    "It's useful to have a single number which summarizes the performance of a model. \n",
    "\n",
    "The intercept is the value predicted by the model when all predictors are zero. \n",
    "\n",
    "The slope represents how rapidly the model changes when that predictor changes. The coefficients attribute gives access to those values. There's a coefficient for each of the predictors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight duration model: Just distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|duration|prediction        |\n",
      "+--------+------------------+\n",
      "|385     |359.2475231916086 |\n",
      "|379     |345.7063569756502 |\n",
      "|130     |133.66228488999982|\n",
      "|230     |238.81435774017962|\n",
      "|64      |72.99180832464427 |\n",
      "+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17.023657662904867"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import round\n",
    "flights_km = flights.withColumn(\"km\", round(flights.mile * 1.60934, 0)).drop(\"mile\")\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=  [\"km\"], outputCol=\"features\")\n",
    "output = assembler.transform(flights_km)\n",
    "\n",
    "flight_train, flight_test = output.randomSplit([0.8, 0.2], 13)\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "regression = LinearRegression(labelCol=\"duration\").fit(flight_train)\n",
    "\n",
    "predictions = regression.transform(flight_test)\n",
    "predictions.select(\"duration\", \"prediction\").show(5, False)\n",
    "RegressionEvaluator(labelCol=\"duration\").evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.39649642725724\n",
      "[0.07564897327351065]\n",
      "793.1370037643285\n"
     ]
    }
   ],
   "source": [
    "inter = regression.intercept\n",
    "print(inter)\n",
    "\n",
    "coefs = regression.coefficients\n",
    "print(coefs)\n",
    "\n",
    "minutes_per_km = regression.coefficients[0]\n",
    "\n",
    "avg_speed = 60 / minutes_per_km\n",
    "\n",
    "print(avg_speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight duration model: Adding origin airport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|duration|prediction        |\n",
      "+--------+------------------+\n",
      "|385     |377.7863176281456 |\n",
      "|379     |364.4835911703198 |\n",
      "|130     |132.02676932478195|\n",
      "|230     |259.4738007518407 |\n",
      "|64      |72.42460944111582 |\n",
      "+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.012777355873434"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_m = flights_onehot.withColumn(\"km\", round(flights_onehot.mile * 1.60934, 0)).drop(\"mile\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=  [\"km\",\"org_dummy\"], outputCol=\"features\")\n",
    "output = assembler.transform(flights_m)\n",
    "\n",
    "flight_train, flight_test = output.randomSplit([0.8, 0.2], 13)\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "regression = LinearRegression(labelCol=\"duration\").fit(flight_train)\n",
    "\n",
    "predictions = regression.transform(flight_test)\n",
    "predictions.select(\"duration\", \"prediction\").show(5, False)\n",
    "RegressionEvaluator(labelCol=\"duration\").evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values for km and org_dummy have been assembled into features, which has eight columns with sparse representation. 0 is km and categorical variables are indexed from 1 to 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|features              |\n",
      "+----------------------+\n",
      "|(8,[0,3],[3465.0,1.0])|\n",
      "|(8,[0,1],[509.0,1.0]) |\n",
      "|(8,[0,2],[542.0,1.0]) |\n",
      "|(8,[0,1],[1989.0,1.0])|\n",
      "|(8,[0,1],[415.0,1.0]) |\n",
      "+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.select(\"features\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07431690758561862,28.413496002892245,20.400159408670234,52.560025885941116,46.64807165450426,18.29933170052044,15.504667559982039,17.58313343757769]\n",
      "\n",
      "807.3532921277102\n",
      "15.919322370859733\n",
      "68.47934825680085\n",
      "62.56739402536399\n"
     ]
    }
   ],
   "source": [
    "print(regression.coefficients)\n",
    "print()\n",
    "\n",
    "avg_speed_hour = 60 / regression.coefficients[0]\n",
    "print(avg_speed_hour)\n",
    "\n",
    "inter = regression.intercept # Average minutes on ground at OGG\n",
    "print(inter)\n",
    "\n",
    "avg_ground_jfk = inter + regression.coefficients[3]\n",
    "print(avg_ground_jfk)\n",
    "\n",
    "avg_ground_lga = inter + regression.coefficients[4]\n",
    "print(avg_ground_lga)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bucketing & Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest improvements in ML model performance are ofthen achieved by carefully manipulating features.\n",
    "\n",
    "It's often convenient to convert a continuous variable, like age or height, into discrete values. This can be done by assigning values to buckets or bins with well defined boundaries. Resulting categorical variable is ofthen a more powerful predictor than the original continuous variable. To use them in a regression model, they first need to be one-hot encoded.\n",
    "\n",
    "There are many other approaches to engineering new features. Applying arithmetic operations to one or more columns to create new features. Powerful new features are ofthen discovered through trial and error. Selecting only the relevant predictors is important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucketing departure time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|depart|depart_bucket|\n",
      "+------+-------------+\n",
      "|  9.48|          3.0|\n",
      "| 16.33|          5.0|\n",
      "|  6.17|          2.0|\n",
      "| 10.33|          3.0|\n",
      "|  8.92|          2.0|\n",
      "+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+-------------+-------------+\n",
      "|depart|depart_bucket| depart_dummy|\n",
      "+------+-------------+-------------+\n",
      "|  9.48|          3.0|(7,[3],[1.0])|\n",
      "| 16.33|          5.0|(7,[5],[1.0])|\n",
      "|  6.17|          2.0|(7,[2],[1.0])|\n",
      "| 10.33|          3.0|(7,[3],[1.0])|\n",
      "|  8.92|          2.0|(7,[2],[1.0])|\n",
      "+------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Bucketizer, OneHotEncoder\n",
    "\n",
    "buckets = Bucketizer(splits=[0,3,6,9,12,15,18,21,24], inputCol=\"depart\", outputCol=\"depart_bucket\")\n",
    "bucketed = buckets.transform(flights)\n",
    "bucketed.select(\"depart\", \"depart_bucket\").show(5)\n",
    "\n",
    "onehot = OneHotEncoder(inputCols=[\"depart_bucket\"], outputCols=[\"depart_dummy\"])\n",
    "flights_onehot = onehot.fit(bucketed).transform(bucketed)\n",
    "flights_onehot.select(\"depart\", \"depart_bucket\", \"depart_dummy\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now departure time can be added to the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight duration model: Adding departure time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+------+--------+-----+-------+------+-------------+-------------+-------------+\n",
      "|mon|dom|dow|carrier|flight|org|depart|duration|delay|org_idx|    km|    org_dummy|depart_bucket| depart_dummy|\n",
      "+---+---+---+-------+------+---+------+--------+-----+-------+------+-------------+-------------+-------------+\n",
      "| 11| 20|  6|     US|    19|JFK|  9.48|     351| null|    2.0|3465.0|(7,[2],[1.0])|          3.0|(7,[3],[1.0])|\n",
      "|  0| 22|  2|     UA|  1107|ORD| 16.33|      82|   30|    0.0| 509.0|(7,[0],[1.0])|          5.0|(7,[5],[1.0])|\n",
      "|  2| 20|  4|     UA|   226|SFO|  6.17|      82|   -8|    1.0| 542.0|(7,[1],[1.0])|          2.0|(7,[2],[1.0])|\n",
      "|  9| 13|  1|     AA|   419|ORD| 10.33|     195|   -5|    0.0|1989.0|(7,[0],[1.0])|          3.0|(7,[3],[1.0])|\n",
      "|  4|  2|  5|     AA|   325|ORD|  8.92|      65| null|    0.0| 415.0|(7,[0],[1.0])|          2.0|(7,[2],[1.0])|\n",
      "|  5|  2|  1|     UA|   704|SFO|  7.98|     102|    2|    1.0| 885.0|(7,[1],[1.0])|          2.0|(7,[2],[1.0])|\n",
      "|  7|  2|  6|     AA|   380|ORD| 10.83|     135|   54|    0.0|1180.0|(7,[0],[1.0])|          3.0|(7,[3],[1.0])|\n",
      "|  1| 16|  6|     UA|  1477|ORD|   8.0|     232|   -7|    0.0|2317.0|(7,[0],[1.0])|          2.0|(7,[2],[1.0])|\n",
      "|  1| 22|  5|     UA|   620|SJC|  7.98|     250|  -13|    4.0|2943.0|(7,[4],[1.0])|          2.0|(7,[2],[1.0])|\n",
      "| 11|  8|  1|     OO|  5590|SFO|  7.77|      60|   88|    1.0| 254.0|(7,[1],[1.0])|          2.0|(7,[2],[1.0])|\n",
      "|  4| 26|  1|     AA|  1144|SFO| 13.25|     210|  -10|    1.0|2356.0|(7,[1],[1.0])|          4.0|(7,[4],[1.0])|\n",
      "|  4| 25|  0|     AA|   321|ORD| 13.75|     160|   31|    0.0|1574.0|(7,[0],[1.0])|          4.0|(7,[4],[1.0])|\n",
      "|  8| 30|  2|     UA|   646|ORD| 13.28|     151|   16|    0.0|1157.0|(7,[0],[1.0])|          4.0|(7,[4],[1.0])|\n",
      "|  3| 16|  3|     UA|   107|ORD|   9.0|     264|    3|    0.0|2808.0|(7,[0],[1.0])|          3.0|(7,[3],[1.0])|\n",
      "|  0|  3|  4|     AA|  1559|LGA| 17.08|     190|   32|    3.0|1765.0|(7,[3],[1.0])|          5.0|(7,[5],[1.0])|\n",
      "|  5|  9|  1|     UA|   770|SFO|  12.7|     158|   20|    1.0|1556.0|(7,[1],[1.0])|          4.0|(7,[4],[1.0])|\n",
      "|  3| 10|  4|     B6|   937|ORD| 17.58|     265|  155|    0.0|2792.0|(7,[0],[1.0])|          5.0|(7,[5],[1.0])|\n",
      "| 11| 15|  1|     AA|  2303|ORD|  6.75|     160|   23|    0.0|1291.0|(7,[0],[1.0])|          2.0|(7,[2],[1.0])|\n",
      "|  8| 18|  4|     UA|   802|SJC|  6.33|     160|   17|    4.0|1526.0|(7,[4],[1.0])|          2.0|(7,[2],[1.0])|\n",
      "|  2| 14|  5|     B6|    71|JFK|  6.17|     166|    0|    2.0|1519.0|(7,[2],[1.0])|          2.0|(7,[2],[1.0])|\n",
      "+---+---+---+-------+------+---+------+--------+-----+-------+------+-------------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights = spark.read.csv(\"flights.csv\", sep=\",\", header=True, inferSchema=True, nullValue=\"NA\")\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"org\", outputCol=\"org_idx\")\n",
    "indexer_model = indexer.fit(flights)\n",
    "flights = indexer_model.transform(flights)\n",
    "\n",
    "flights = flights.withColumn(\"km\", round(flights.mile * 1.60934, 0)).drop(\"mile\")\n",
    "\n",
    "onehot = OneHotEncoder(inputCols=[\"org_idx\"], outputCols=[\"org_dummy\"])\n",
    "onehot = onehot.fit(flights)\n",
    "flights = onehot.transform(flights)\n",
    "\n",
    "buckets = Bucketizer(splits=[0,3,6,9,12,15,18,21,24], inputCol=\"depart\", outputCol=\"depart_bucket\")\n",
    "flights = buckets.transform(flights)\n",
    "\n",
    "onehot = OneHotEncoder(inputCols=[\"depart_bucket\"], outputCols=[\"depart_dummy\"])\n",
    "flights = onehot.fit(flights).transform(flights)\n",
    "flights.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+-------------+------------------------------+\n",
      "|km    |org_dummy    |depart_dummy |features                      |\n",
      "+------+-------------+-------------+------------------------------+\n",
      "|3465.0|(7,[2],[1.0])|(7,[3],[1.0])|(15,[0,3,11],[3465.0,1.0,1.0])|\n",
      "|509.0 |(7,[0],[1.0])|(7,[5],[1.0])|(15,[0,1,13],[509.0,1.0,1.0]) |\n",
      "|542.0 |(7,[1],[1.0])|(7,[2],[1.0])|(15,[0,2,10],[542.0,1.0,1.0]) |\n",
      "|1989.0|(7,[0],[1.0])|(7,[3],[1.0])|(15,[0,1,11],[1989.0,1.0,1.0])|\n",
      "|415.0 |(7,[0],[1.0])|(7,[2],[1.0])|(15,[0,1,10],[415.0,1.0,1.0]) |\n",
      "+------+-------------+-------------+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=  [\"km\",\"org_dummy\", \"depart_dummy\"], outputCol=\"features\")\n",
    "flights = assembler.transform(flights)\n",
    "flights.select(\"km\",\"org_dummy\", \"depart_dummy\", \"features\").show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.68279557023109\n",
      "10.470157159054379\n",
      "-2.7425333357930377\n",
      "48.90395499832853\n"
     ]
    }
   ],
   "source": [
    "flight_train, flight_test = flights.randomSplit([0.8, 0.2], 13)\n",
    "\n",
    "regression = LinearRegression(labelCol=\"duration\").fit(flight_train)\n",
    "predictions = regression.transform(flight_test)\n",
    "\n",
    "print(RegressionEvaluator(labelCol=\"duration\").evaluate(predictions))\n",
    "\n",
    "# Average minutes on ground at OGG for flights departing between 21:00 and 24:00\n",
    "avg_night_ogg = regression.intercept + regression.coefficients[8]\n",
    "print(avg_eve_ogg)\n",
    "\n",
    "# Average minutes on ground at OGG for flights departing between 00:00 and 03:00\n",
    "avg_night_ogg = regression.intercept + regression.coefficients[8]\n",
    "print(avg_night_ogg)\n",
    "\n",
    "\n",
    "# Average minutes on ground at JFK for flights departing between 00:00 and 03:00\n",
    "avg_night_jfk = regression.intercept + regression.coefficients[8] + regression.coefficients[3]\n",
    "print(avg_night_jfk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients quantify the effect of the coressponding features. More features imply more coefficients. Parsimonious model is the one that has the minimum required number of predictors by selecting the best subset of columns. One such approach to feature selection known as \"penalized regression\". The model is penalized or punished for having too many coefficients. With penalized regression an additional \"regularization\" or \"shrinkage\" term is added to the loss funtion. The regularization term can be Lasso which uses absolute value of the coefficients or Ridge which uses square of the coefficients. The strength of the regularization is determined by lambda.\n",
    "\n",
    "Coefficients that are non zero are contributing to the model but it is unlikely that all the features are equally important for predicting. \n",
    "\n",
    "For Ridge regression give value of zero for elasticNetParam and use regParam to specify the strength. By using Ridge regression the coefficients are now smaller since they are shrunk. \n",
    "For Lasso regression set elasticNetParam to 1. The coefficient values can indicate the most important predictors by setting the rest to zero.\n",
    "\n",
    "A simpler model with no significant loss in performance can be created by using these predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight duration model: More features!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Adding some features might improve the model. Adding other features might make it worse. More features will always make the model more complicated and difficult to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test RMSE is 10.603426704688353\n",
      "\n",
      "[0.07442260365703582,27.167707368706242,19.995665949017873,51.730261452801216,45.67716622066441,17.52240710954814,14.814703580321478,17.066898599484237,-13.638548949659642,0.9350467119010547,4.082754272794686,6.884410153783628,4.594492831905297,8.920085499289964,8.660386163384594,0.3366200590787332,0.05343697665105215,-0.33509170185988363,0.1804058184014835,0.2068323004067617,0.13499047028356215,-2.01346827559683,-2.5175690364624708,-2.2060718771750953,-3.578897387139923,-4.381160055596363,-4.261759154832496,-4.642295907247864,-4.371847828627821,-4.038276122473209,-2.8784616188212446,-0.8034853740251807]\n"
     ]
    }
   ],
   "source": [
    "flights = flights.drop(\"features\")\n",
    "\n",
    "onehot = OneHotEncoder(inputCols=[\"mon\"], outputCols=[\"mon_dummy\"])\n",
    "flights = onehot.fit(flights).transform(flights)\n",
    "\n",
    "onehot = OneHotEncoder(inputCols=[\"dow\"], outputCols=[\"dow_dummy\"])\n",
    "flights = onehot.fit(flights).transform(flights)\n",
    "\n",
    "assembler = VectorAssembler(inputCols=  [\"km\",\"org_dummy\", \"depart_dummy\", \"dow_dummy\", \"mon_dummy\"], outputCol=\"features\")\n",
    "flights = assembler.transform(flights)\n",
    "\n",
    "flight_train, flight_test = flights.randomSplit([0.8, 0.2], 13)\n",
    "\n",
    "regression = LinearRegression(labelCol=\"duration\").fit(flight_train)\n",
    "predictions = regression.transform(flight_test)\n",
    "rmse = RegressionEvaluator(labelCol=\"duration\").evaluate(predictions)\n",
    "print(\"The test RMSE is\", rmse)\n",
    "print()\n",
    "coeffs = regression.coefficients\n",
    "print(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all those non-zero coefficients the model is a little hard to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight duration model: Regularisation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the best value for the regularization strength using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test RMSE is 11.606244213337014\n",
      "[0.07352946004541223,5.479348461026474,0.0,29.003106728687897,21.899509851164623,0.0,-2.4152381011777506,0.0,0.0,0.0,0.0,0.0,0.0,1.2056808785451512,1.0618468972388517,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
      "Number of coefficients equal to 0: 25\n"
     ]
    }
   ],
   "source": [
    "regression = LinearRegression(labelCol=\"duration\", regParam=1, elasticNetParam=1).fit(flight_train)\n",
    "rmse = RegressionEvaluator(labelCol=\"duration\").evaluate(regression.transform(flight_test))\n",
    "print(\"The test RMSE is\", rmse)\n",
    "coeffs = regression.coefficients\n",
    "print(coeffs)\n",
    "\n",
    "zero_coeff = sum([beta==0 for beta in regression.coefficients])\n",
    "print(\"Number of coefficients equal to 0:\", zero_coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularisation produced a far simpler model with similar test performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
