{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the methods defined by Spark's DataFrame class to perform common data operations.\n",
    "\n",
    "Columns wise operations can be done by using the .withColumn() method.\n",
    "\n",
    "You can use spark.table(\"...\") to create dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = spark.table(\"flights\")\n",
    "flights.show()\n",
    "flights = flights.withColumn(\"duration_hrs\", flights.air_time / 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL in a nutshell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the code above you can do column-wise calculations with SQL.\n",
    "\n",
    "SELECT origin, dest, air_time / 60 AS duration_hrs FROM flights;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the .filter() method is the Spark counterpart of SQL's WHERE clause. The .filter() method takes either an expression that would follow the WHERE clause of a SQL expression as a string, or a Spark Column of boolean (True/False) values.\n",
    "\n",
    "Spark's .filter() can accept any expression that could go in the WHEREclause of a SQL query (in this case, \"air_time > 120\"), as long as it is passed as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_flights1 = flights.filter(\"distance > 1000\")\n",
    "long_flights2 = flights.filter(flights.distance > 1000)\n",
    "\n",
    "print(long_flights1.show())\n",
    "print(long_flights2.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Spark variant of SQL's SELECT is the .select() method. This method takes multiple arguments - one for each column you want to select. These arguments can either be the column name as a string or a column object.\n",
    "\n",
    "When you pass a column object, you can perform operations like addition or subtraction on the column to change the data contained in it, much like inside .withColumn().\n",
    "\n",
    ".select() returns only the columns you specify, while .withColumn() returns all the columns of the DataFrame in addition to the one you defined. It's often a good idea to drop columns you don't need at the beginning of an operation. In this case, you would use .select() and not .withColumn()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected1 = flights.select(\"tailnum\", \"origin\", \"dest\")\n",
    "\n",
    "temp = flights.select(flights.origin, flights.dest, flights.carrier)\n",
    "\n",
    "filterA = flights.origin = \"SEA\"\n",
    "filterB = flights.dest = \"PDX\"\n",
    "\n",
    "selected2 = temp.filter(filterA).filter(filterB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting II\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're selecting a column using the df.colName notation, you can perform any column operation and the .select() method will return the transformed column.  You can also use the .alias() method to rename a column you're selecting. The equivalent Spark DataFrame method .selectExpr() takes SQL expressions as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_speed = (flights.distance / (flights.air_time / 60)).alias(\"avg_speed\")\n",
    "\n",
    "speed1 = flights.select(\"origin\", \"dest\", \"tailnum\", avg_speed)\n",
    "\n",
    "speed2 = flights.selectExpr(\"origin\", \"dest\", \"tailnum\", \"distance/(air_time/60) as avg_speed\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the common aggregation methods, like .min(), .max(), and .count() are GroupedData methods. These are created by calling the .groupBy() DataFrame method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fligts.filter(flights.origin = \"PDX\").groupBy().min(\"distance\").show()\n",
    "\n",
    "fligts.filter(\"origin == 'SEA'\").groupBy().max(\"air_time\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating II\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.filter(flights.carrier == \"DL\").filter(flights.origin == \"SEA\").groupBy().avg(\"air_time\").show()\n",
    "\n",
    "flights.withColumn(\"duration_hrs\", flights.air_time/60).groupBy().sum(\"duration_hrs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping and Aggregating I\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the name of one or more columns in your DataFrame to the .groupBy() method, the aggregation methods behave like when you use a GROUP BY statement in a SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_plane = flights.groupBy(\"tailnum\")\n",
    "by_plane.count().show()\n",
    "\n",
    "by_origin = flights.groupBy(\"origin\")\n",
    "by_origin.avg(\"air_time\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping and Aggregating II\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the GroupedData methods, there is also the .agg() method. This method lets you pass an aggregate column expression that uses any of the aggregate functions from the pyspark.sql.functions submodule. This submodule contains many useful functions for computing things like standard deviations. All the aggregation functions in this submodule take the name of a column in a GroupedData table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "by_month_dest = flights.groupBy(\"month\", \"dest\")\n",
    "by_month_dest.avg(\"dep_delay\").show()\n",
    "\n",
    "by_month_dest.agg(F.stddev(\"dep_delay\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A join will combine two different tables along a column that they share. This column is called the key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PySpark, joins are performed using the DataFrame method .join()\n",
    "\n",
    "This method takes three arguments. The first is the second DataFrame that you want to join with the first one. The second argument, on, is the name of the key column(s) as a string. The names of the key column(s) must be the same in each table. The third argument, how, specifies the kind of join to perform. In this course we'll always use the value how=\"leftouter\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(airports.show())\n",
    "\n",
    "airports = airports.withColumnRenamed(\"faa\",\"dest\")\n",
    "flights_with_airports = flights.join(airports, on=\"dest\", how=\"leftouter\")\n",
    "print(flights_with_airports.show())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
